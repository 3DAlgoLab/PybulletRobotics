{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [ロボットアーム](#toc1_)    \n",
    "- [pybulletの起動](#toc2_)    \n",
    "- [pybulletの初期設定](#toc3_)    \n",
    "- [ロボットアームの生成](#toc4_)    \n",
    "- [使用する関数の定義](#toc5_)    \n",
    "- [カラーのオブジェクトの生成](#toc6_)    \n",
    "- [カメラの生成](#toc7_)    \n",
    "- [カメラのパラメータの設定](#toc8_)    \n",
    "- [画像の取得](#toc9_)    \n",
    "- [カラーのオブジェクトの位置の推定](#toc10_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[ロボットアーム](#toc0_)\n",
    "\n",
    "本notebookでは6軸のロボットアームを生成し、「固定されたカメラ」から指定したカラーのオブジェクトの位置を推定する方法を紹介します。\n",
    "\n",
    "（今回は、固定されたカメラから位置を推定するので、アームの制御は行いません。）\n",
    "\n",
    "（pybulletで使用可能な関数がまとめられたマニュアルについては[こちら](https://github.com/bulletphysics/bullet3/blob/master/docs/pybullet_quickstartguide.pdf)を参照してください。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[pybulletの起動](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Mesa\n",
      "GL_RENDERER=llvmpipe (LLVM 15.0.7, 256 bits)\n",
      "GL_VERSION=4.5 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.50\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.5 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Mesa\n",
      "Renderer = llvmpipe (LLVM 15.0.7, 256 bits)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    }
   ],
   "source": [
    "import pybullet\n",
    "import pybullet_data\n",
    "physicsClient = pybullet.connect(pybullet.GUI) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[pybulletの初期設定](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven = Mesa\n",
      "ven = Mesa\n"
     ]
    }
   ],
   "source": [
    "pybullet.resetSimulation() # シミュレーション空間をリセット\n",
    "pybullet.setAdditionalSearchPath(pybullet_data.getDataPath()) # pybulletに必要なデータへのパスを追加\n",
    "pybullet.setGravity(0.0, 0.0, -9.8) # 地球上における重力に設定\n",
    "timeStep = 1./240.\n",
    "pybullet.setTimeStep(timeStep) # 1stepあたりに経過する時間の設定\n",
    "\n",
    "#床の読み込み\n",
    "planeId = pybullet.loadURDF(\"plane.urdf\")\n",
    "\n",
    "# GUIモードの際のカメラの位置などを設定\n",
    "cameraDistance = 3.5\n",
    "cameraYaw = 180.0 # deg\n",
    "cameraPitch = -40 # deg\n",
    "cameraTargetPosition = [0, 0.5, 0.0]\n",
    "pybullet.resetDebugVisualizerCamera(cameraDistance, cameraYaw, cameraPitch, cameraTargetPosition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[ロボットアームの生成](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: target_position_vertual_link\n"
     ]
    }
   ],
   "source": [
    "# ロボットの読み込み\n",
    "armStartPos = [0, 0, 0.0]  # 初期位置(x,y,z)を設定\n",
    "armStartOrientation = pybullet.getQuaternionFromEuler([0,0,0])  # 初期姿勢(roll, pitch, yaw)を設定\n",
    "armId = pybullet.loadURDF(\"../urdf/simple6d_arm_with_gripper.urdf\", armStartPos, armStartOrientation, useFixedBase=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[使用する関数の定義](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def DetectColorObjPose(targetRGB, rgbImg, depthImg):\n",
    "    \"\"\"\n",
    "    最初に検出された色物体の中心位置、深度、姿勢を取得する関数\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    targetRGB : list\n",
    "        検出したい色のRGB\n",
    "    rgbImg : numpy.ndarray\n",
    "        カメラ画像（RGB）\n",
    "    depthImg : numpy.ndarray\n",
    "        カメラ画像（Depth）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj_pose : numpy.ndarray\n",
    "        色物体の位置と姿勢（x, y, z, roll, pitch, yaw）\n",
    "    \"\"\"\n",
    "\n",
    "    # カメラ画像をHSV形式に変換\n",
    "    hsvImg = cv2.cvtColor(rgbImg, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # RGBをHSVに変換\n",
    "    targetHsv = cv2.cvtColor(np.uint8([[targetRGB]]), cv2.COLOR_RGB2HSV)[0][0]\n",
    "\n",
    "    # 検出したい色の範囲を指定\n",
    "    lower = np.array([targetHsv[0]-10, 50, 50])\n",
    "    upper = np.array([targetHsv[0]+10, 255, 255])\n",
    "\n",
    "    # 指定した色のみを抽出\n",
    "    mask = cv2.inRange(hsvImg, lower, upper)\n",
    "\n",
    "    # 輪郭を抽出\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 最大面積の輪郭を取得\n",
    "    max_area = 0\n",
    "    max_area_contour = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_area_contour = contour\n",
    "\n",
    "    # 輪郭が見つからなかった場合\n",
    "    if max_area_contour is None:\n",
    "        return None\n",
    "    \n",
    "    # 輪郭の中心位置を取得\n",
    "    M = cv2.moments(max_area_contour)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "    # 輪郭の中心位置における深度を取得\n",
    "    depth = depthImg[cy, cx]\n",
    "\n",
    "    pos = [cx, cy, depth]\n",
    "    \n",
    "\n",
    "\n",
    "    return pos\n",
    "\n",
    "def Rx(theta):\n",
    "    \"\"\"\n",
    "    x軸周りの回転行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        x軸周りの回転行列\n",
    "    \"\"\"\n",
    "    return np.array([[1, 0, 0],\n",
    "                     [0, np.cos(theta), -np.sin(theta)],\n",
    "                     [0, np.sin(theta), np.cos(theta)]])\n",
    "\n",
    "def Ry(theta):\n",
    "    \"\"\"\n",
    "    y軸周りの回転行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        y軸周りの回転行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), 0, np.sin(theta)],\n",
    "                     [0, 1, 0],\n",
    "                     [-np.sin(theta), 0, np.cos(theta)]])\n",
    "\n",
    "def Rz(theta):\n",
    "    \"\"\"\n",
    "    z軸周りの回転行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        z軸周りの回転行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                     [np.sin(theta), np.cos(theta), 0],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "\n",
    "def Hx(theta):\n",
    "    \"\"\"\n",
    "    x軸回りの同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        x軸回りの同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[1, 0, 0, 0],\n",
    "                     [0, np.cos(theta), -np.sin(theta), 0],\n",
    "                     [0, np.sin(theta), np.cos(theta), 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def Hy(theta):\n",
    "    \"\"\"\n",
    "    y軸回りの同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        y軸回りの同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), 0, np.sin(theta), 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [-np.sin(theta), 0, np.cos(theta), 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def Hz(theta):\n",
    "    \"\"\"\n",
    "    z軸回りの同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        z軸回りの同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), -np.sin(theta), 0, 0],\n",
    "                     [np.sin(theta), np.cos(theta), 0, 0],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def Hp(x, y, z):\n",
    "    \"\"\"\n",
    "    平行移動の同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        x方向の移動量\n",
    "    y : float\n",
    "        y方向の移動量\n",
    "    z : float\n",
    "        z方向の移動量\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        平行移動の同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[1, 0, 0, x],\n",
    "                     [0, 1, 0, y],\n",
    "                     [0, 0, 1, z],\n",
    "                     [0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[カラーのオブジェクトの生成](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここを変えると結果が変わります（simpleCameraの画角に収まるように設定してください）####\n",
    "colorBoxPos = [-2.0, 1.5, 0.05] # 色物体の初期位置(x, y, z)を設定\n",
    "#################################################################################\n",
    "\n",
    "colorBoxId = pybullet.loadURDF(\"../urdf/simple_box.urdf\", colorBoxPos, pybullet.getQuaternionFromEuler([0.0, 0.0, 0.0]), globalScaling=0.1, useFixedBase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[カメラの生成](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: base_link\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: target_position_vertual_link\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# ここを変えると結果が変わります（colorBoxがsimpleCameraの画角に収まるように設定してください）####\n",
    "simpleCameraX = 0.0\n",
    "simpleCameraY = 0.0\n",
    "simpleCameraZ = 4.0\n",
    "simpleCameraRoll = 0.0\n",
    "simpleCameraPitch = 0.0\n",
    "simpleCameraYaw = 0.0\n",
    "#################################################################################\n",
    "\n",
    "simpleCameraRoll = math.radians(180.0 + simpleCameraRoll)\n",
    "simpleCameraPitch = math.radians(0.0 + simpleCameraPitch)\n",
    "simpleCameraYaw = math.radians(0.0 + simpleCameraYaw)\n",
    "simpleCameraId = pybullet.loadURDF(\"../urdf/simple_camera.urdf\", [simpleCameraX, simpleCameraY, simpleCameraZ], pybullet.getQuaternionFromEuler([simpleCameraRoll, simpleCameraPitch, simpleCameraYaw]), useFixedBase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[カメラのパラメータの設定](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カメラ設定\n",
    "fov = 60\n",
    "imageWidth = 224\n",
    "imageHeight = 224\n",
    "aspect = imageWidth / imageHeight\n",
    "near = 0.05\n",
    "far = 5\n",
    "projectionMatrix = pybullet.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "# 焦点距離を求める\n",
    "fovRad = np.deg2rad(fov)\n",
    "f = (imageHeight / 2) / np.tan(fovRad / 2)\n",
    "\n",
    "# カメラの内部パラメータ\n",
    "cameraMatrix = np.array([[f, 0, imageWidth//2],\n",
    "                         [0, f, imageHeight//2],\n",
    "                         [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# 歪み係数（ここでは、歪みがないと仮定）\n",
    "distCoeffs = np.array([0.0, 0.0, 0.0, 0.0, 0.0], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc9_'></a>[画像の取得](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleCameraLinkIdx = 0\n",
    "simpleCameraTargetLinkIdx = 1\n",
    "\n",
    "# カメラの位置を取得\n",
    "cameraLinkPose = pybullet.getLinkState(simpleCameraId, simpleCameraLinkIdx)[0] # 手先のカメラリンクの位置\n",
    "cameraTargetLinkPose = pybullet.getLinkState(simpleCameraId, simpleCameraTargetLinkIdx)[0] # カメラリンクの少しだけ前に設定した仮想的なリンクの位置\n",
    "cameraLinkOrientation = pybullet.getEulerFromQuaternion(pybullet.getLinkState(simpleCameraId, simpleCameraLinkIdx)[1]) # 手先のカメラリンクの姿勢\n",
    "\n",
    "# カメラの姿勢に合わせてカメラの上方向のベクトルを回転\n",
    "cameraUpVector = np.array([0, -1, 0]) # デフォルトのカメラの上方向のベクトル\n",
    "R = Rz(simpleCameraYaw)@Ry(simpleCameraPitch)@Rx(simpleCameraRoll)\n",
    "rotateCameraUpVector = R@cameraUpVector\n",
    "\n",
    "# カメラのビュー行列を計算\n",
    "viewMatrix = pybullet.computeViewMatrix(cameraEyePosition=[cameraLinkPose[0], cameraLinkPose[1], cameraLinkPose[2]], cameraTargetPosition=[cameraTargetLinkPose[0], cameraTargetLinkPose[1], cameraTargetLinkPose[2]],cameraUpVector=[rotateCameraUpVector[0], rotateCameraUpVector[1], rotateCameraUpVector[2]])\n",
    "\n",
    "# カメラ画像を取得\n",
    "_, _, rgbImg, depthImg, _ = pybullet.getCameraImage(\n",
    "    width=imageWidth,\n",
    "    height=imageHeight,\n",
    "    viewMatrix=viewMatrix,\n",
    "    projectionMatrix=projectionMatrix,\n",
    "    renderer=pybullet.ER_BULLET_HARDWARE_OPENGL\n",
    ")\n",
    "\n",
    "# 指定した色の物体の位置を取得\n",
    "detectColorRGB = [0, 0, 255] # 検出したい色を指定（ここでは赤色）\n",
    "pos = DetectColorObjPose(detectColorRGB, rgbImg, depthImg)\n",
    "pixelX = pos[0] # x座標（画像上の位置）\n",
    "pixelY = pos[1] # y座標（画像上の位置）\n",
    "normalZ = pos[2] # z座標（0～1に正規化された深度）\n",
    "z = far * near / (far - (far - near) * normalZ) # 0～1に正規化された深度を距離[m]に変換\n",
    "x = (pixelX - imageWidth//2) * z / f # pixelXを距離[m]に変換\n",
    "y = (pixelY - imageHeight//2) * z / f # pixelYを距離[m]に変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[カラーのオブジェクトの位置の推定](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color box obj pose:  -2.0 1.5 0.05\n",
      "estimate color obj pose -1.9903058737195025 1.5078074800905317 0.10001191576652735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ワールド座標系におけるカラーの物体の位置を計算\n",
    "cameraPos = np.array([simpleCameraX, \n",
    "                      simpleCameraY, \n",
    "                      simpleCameraZ])\n",
    "colorObjPosCamera = np.array([x, y, z]) # カメラ座標系における物体の位置\n",
    "colorObjPosWorld = cameraPos + R@colorObjPosCamera # ワールド座標系における物体の位置\n",
    "\n",
    "# ボックスの位置を取得\n",
    "boxPos, boxOrn = pybullet.getBasePositionAndOrientation(colorBoxId)\n",
    "print(\"color box obj pose: \", boxPos[0], boxPos[1], boxPos[2])\n",
    "print(\"estimate color obj pose\", colorObjPosWorld[0], colorObjPosWorld[1], colorObjPosWorld[2])\n",
    "\n",
    "# Pybuletの画面上に、物体の位置を描画\n",
    "pybullet.addUserDebugLine(cameraPos[:3], colorObjPosWorld[:3], lineColorRGB=[1, 0, 0], lineWidth=5)\n",
    "\n",
    "# ボックスの位置を描画\n",
    "pybullet.addUserDebugText(f\"true box pose ({boxPos[0]:.3f}, {boxPos[1]:.3f}, {boxPos[2]:.3f})\", [4.0, 0.5, 0], textColorRGB=[1, 0, 0], textSize=1.3)\n",
    "pybullet.addUserDebugText(f\"eye to hand, estimate box pose ({colorObjPosWorld[0]:.3f}, {colorObjPosWorld[1]:.3f}, {colorObjPosWorld[2]:.3f})\", [4.0, 1.0, 0.0], textColorRGB=[1, 0, 0], textSize=1.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
