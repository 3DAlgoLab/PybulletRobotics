{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [ロボットアーム](#toc1_)    \n",
    "- [pybulletの起動](#toc2_)    \n",
    "- [pybulletの初期設定](#toc3_)    \n",
    "- [ロボットアームの生成](#toc4_)    \n",
    "- [使用する関数の定義](#toc5_)    \n",
    "- [カラーのオブジェクトの生成](#toc6_)    \n",
    "- [カメラの生成](#toc7_)    \n",
    "- [カメラのパラメータの設定](#toc8_)    \n",
    "- [画像の取得](#toc9_)    \n",
    "- [カラーのオブジェクトの位置の推定](#toc10_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[ロボットアーム](#toc0_)\n",
    "\n",
    "本notebookでは6軸のロボットアームを生成し、「固定されたカメラ」から指定したカラーのオブジェクトの位置を推定する方法を紹介します。\n",
    "\n",
    "（今回は、固定されたカメラから位置を推定するので、アームの制御は行いません。）\n",
    "\n",
    "（pybulletで使用可能な関数がまとめられたマニュアルについては[こちら](https://github.com/bulletphysics/bullet3/blob/master/docs/pybullet_quickstartguide.pdf)を参照してください。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[pybulletの起動](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Mesa\n",
      "GL_RENDERER=llvmpipe (LLVM 15.0.7, 256 bits)\n",
      "GL_VERSION=4.5 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.50\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.5 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Mesa\n",
      "Renderer = llvmpipe (LLVM 15.0.7, 256 bits)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    }
   ],
   "source": [
    "import pybullet\n",
    "import pybullet_data\n",
    "physics_client = pybullet.connect(pybullet.GUI) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[pybulletの初期設定](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven = Mesa\n",
      "ven = Mesa\n"
     ]
    }
   ],
   "source": [
    "pybullet.resetSimulation() # シミュレーション空間をリセット\n",
    "pybullet.setAdditionalSearchPath(pybullet_data.getDataPath()) # pybulletに必要なデータへのパスを追加\n",
    "pybullet.setGravity(0.0, 0.0, -9.8) # 地球上における重力に設定\n",
    "time_step = 1./240.\n",
    "pybullet.setTimeStep(time_step) # 1stepあたりに経過する時間の設定\n",
    "\n",
    "#床の読み込み\n",
    "plane_id = pybullet.loadURDF(\"plane.urdf\")\n",
    "\n",
    "# GUIモードの際のカメラの位置などを設定\n",
    "camera_distance = 3.5\n",
    "camera_yaw = 180.0 # deg\n",
    "camera_pitch = -40 # deg\n",
    "cameraTargetPosition = [0, 0.5, 0.0]\n",
    "pybullet.resetDebugVisualizerCamera(camera_distance, camera_yaw, camera_pitch, cameraTargetPosition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[ロボットアームの生成](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: target_position_vertual_link\n"
     ]
    }
   ],
   "source": [
    "# ロボットの読み込み\n",
    "arm_start_pos = [0, 0, 0.0]  # 初期位置(x,y,z)を設定\n",
    "arm_start_orientation = pybullet.getQuaternionFromEuler([0,0,0])  # 初期姿勢(roll, pitch, yaw)を設定\n",
    "arm_id = pybullet.loadURDF(\"../urdf/simple6d_arm_with_gripper.urdf\", arm_start_pos, arm_start_orientation, useFixedBase=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[使用する関数の定義](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_color_obj_pose(target_rgb, rgb_img, depth_img):\n",
    "    \"\"\"\n",
    "    最初に検出された色物体の中心位置、深度、姿勢を取得する関数\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target_rgb : list\n",
    "        検出したい色のRGB\n",
    "    rgb_img : numpy.ndarray\n",
    "        カメラ画像（RGB）\n",
    "    depth_img : numpy.ndarray\n",
    "        カメラ画像（Depth）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj_pose : numpy.ndarray\n",
    "        色物体の位置と姿勢（x, y, z, roll, pitch, yaw）\n",
    "    \"\"\"\n",
    "\n",
    "    # カメラ画像をHSV形式に変換\n",
    "    hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # RGBをHSVに変換\n",
    "    target_hsv = cv2.cvtColor(np.uint8([[target_rgb]]), cv2.COLOR_RGB2HSV)[0][0]\n",
    "\n",
    "    # 検出したい色の範囲を指定\n",
    "    lower = np.array([target_hsv[0]-10, 50, 50])\n",
    "    upper = np.array([target_hsv[0]+10, 255, 255])\n",
    "\n",
    "    # 指定した色のみを抽出\n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "\n",
    "    # 輪郭を抽出\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 最大面積の輪郭を取得\n",
    "    max_area = 0\n",
    "    max_area_contour = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_area_contour = contour\n",
    "\n",
    "    # 輪郭が見つからなかった場合\n",
    "    if max_area_contour is None:\n",
    "        return None\n",
    "    \n",
    "    # 輪郭の中心位置を取得\n",
    "    M = cv2.moments(max_area_contour)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "    # 輪郭の中心位置における深度を取得\n",
    "    depth = depth_img[cy, cx]\n",
    "\n",
    "    pos = [cx, cy, depth]\n",
    "    \n",
    "    return pos\n",
    "\n",
    "def Rx(theta):\n",
    "    \"\"\"\n",
    "    x軸周りの回転行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        x軸周りの回転行列\n",
    "    \"\"\"\n",
    "    return np.array([[1, 0, 0],\n",
    "                     [0, np.cos(theta), -np.sin(theta)],\n",
    "                     [0, np.sin(theta), np.cos(theta)]])\n",
    "\n",
    "def Ry(theta):\n",
    "    \"\"\"\n",
    "    y軸周りの回転行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        y軸周りの回転行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), 0, np.sin(theta)],\n",
    "                     [0, 1, 0],\n",
    "                     [-np.sin(theta), 0, np.cos(theta)]])\n",
    "\n",
    "def Rz(theta):\n",
    "    \"\"\"\n",
    "    z軸周りの回転行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        z軸周りの回転行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                     [np.sin(theta), np.cos(theta), 0],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "\n",
    "def Hx(theta):\n",
    "    \"\"\"\n",
    "    x軸回りの同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        x軸回りの同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[1, 0, 0, 0],\n",
    "                     [0, np.cos(theta), -np.sin(theta), 0],\n",
    "                     [0, np.sin(theta), np.cos(theta), 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def Hy(theta):\n",
    "    \"\"\"\n",
    "    y軸回りの同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        y軸回りの同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), 0, np.sin(theta), 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [-np.sin(theta), 0, np.cos(theta), 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def Hz(theta):\n",
    "    \"\"\"\n",
    "    z軸回りの同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        回転角度[rad]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        z軸回りの同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta), -np.sin(theta), 0, 0],\n",
    "                     [np.sin(theta), np.cos(theta), 0, 0],\n",
    "                     [0, 0, 1, 0],\n",
    "                     [0, 0, 0, 1]])\n",
    "\n",
    "def Hp(x, y, z):\n",
    "    \"\"\"\n",
    "    平行移動の同次変換行列を求める\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        x方向の移動量\n",
    "    y : float\n",
    "        y方向の移動量\n",
    "    z : float\n",
    "        z方向の移動量\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        平行移動の同次変換行列\n",
    "    \"\"\"\n",
    "    return np.array([[1, 0, 0, x],\n",
    "                     [0, 1, 0, y],\n",
    "                     [0, 0, 1, z],\n",
    "                     [0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[カラーのオブジェクトの生成](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここを変えると結果が変わります（simpleCameraの画角に収まるように設定してください）####\n",
    "color_box_pos = [-2.0, 1.5, 0.05] # 色物体の初期位置(x, y, z)を設定\n",
    "#################################################################################\n",
    "\n",
    "color_box_id = pybullet.loadURDF(\"../urdf/simple_box.urdf\", color_box_pos, pybullet.getQuaternionFromEuler([0.0, 0.0, 0.0]), globalScaling=0.1, useFixedBase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[カメラの生成](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: base_link\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: target_position_vertual_link\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# ここを変えると結果が変わります（colorBoxがsimpleCameraの画角に収まるように設定してください）####\n",
    "SIMPLE_CAMERA_X = 0.0\n",
    "SIMPLE_CAMERA_Y = 0.0\n",
    "SIMPLE_CAMERA_Z = 4.0\n",
    "SIMPLE_CAMERA_ROLL = 0.0\n",
    "SIMPLE_CAMERA_PITCH = 0.0\n",
    "SIMPLE_CAMERA_YAW = 0.0\n",
    "#################################################################################\n",
    "\n",
    "SIMPLE_CAMERA_ROLL = math.radians(180.0 + SIMPLE_CAMERA_ROLL)\n",
    "SIMPLE_CAMERA_PITCH = math.radians(0.0 + SIMPLE_CAMERA_PITCH)\n",
    "SIMPLE_CAMERA_YAW = math.radians(0.0 + SIMPLE_CAMERA_YAW)\n",
    "simple_camera_id = pybullet.loadURDF(\"../urdf/simple_camera.urdf\", [SIMPLE_CAMERA_X, SIMPLE_CAMERA_Y, SIMPLE_CAMERA_Z], pybullet.getQuaternionFromEuler([SIMPLE_CAMERA_ROLL, SIMPLE_CAMERA_PITCH, SIMPLE_CAMERA_YAW]), useFixedBase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[カメラのパラメータの設定](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カメラ設定\n",
    "fov = 60\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "aspect = image_width / image_height\n",
    "near = 0.05\n",
    "far = 5\n",
    "projection_matrix = pybullet.computeProjectionMatrixFOV(fov, aspect, near, far)\n",
    "\n",
    "# 焦点距離を求める\n",
    "fov_rad = np.deg2rad(fov)\n",
    "f = (image_height / 2) / np.tan(fov_rad / 2)\n",
    "\n",
    "# カメラの内部パラメータ\n",
    "camera_matrix = np.array([[f, 0, image_width//2],\n",
    "                         [0, f, image_height//2],\n",
    "                         [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "# 歪み係数（ここでは、歪みがないと仮定）\n",
    "dist_coeffs = np.array([0.0, 0.0, 0.0, 0.0, 0.0], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc9_'></a>[画像の取得](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_CAMERA_LINK_IDX = 0\n",
    "SIMPLE_CAMERA_TARGET_LINK_IDX = 1\n",
    "\n",
    "# カメラの位置を取得\n",
    "camera_link_pose = pybullet.getLinkState(simple_camera_id, SIMPLE_CAMERA_LINK_IDX)[0] # 手先のカメラリンクの位置\n",
    "camera_target_link_pose = pybullet.getLinkState(simple_camera_id, SIMPLE_CAMERA_TARGET_LINK_IDX)[0] # カメラリンクの少しだけ前に設定した仮想的なリンクの位置\n",
    "camera_link_orientation = pybullet.getEulerFromQuaternion(pybullet.getLinkState(simple_camera_id, SIMPLE_CAMERA_LINK_IDX)[1]) # 手先のカメラリンクの姿勢\n",
    "\n",
    "# カメラの姿勢に合わせてカメラの上方向のベクトルを回転\n",
    "camera_up_vector = np.array([0, -1, 0]) # デフォルトのカメラの上方向のベクトル\n",
    "R = Rz(SIMPLE_CAMERA_YAW)@Ry(SIMPLE_CAMERA_PITCH)@Rx(SIMPLE_CAMERA_ROLL)\n",
    "rotate_camera_up_vector = R@camera_up_vector\n",
    "\n",
    "# カメラのビュー行列を計算\n",
    "view_matrix = pybullet.computeViewMatrix(cameraEyePosition=[camera_link_pose[0], camera_link_pose[1], camera_link_pose[2]], cameraTargetPosition=[camera_target_link_pose[0], camera_target_link_pose[1], camera_target_link_pose[2]],cameraUpVector=[rotate_camera_up_vector[0], rotate_camera_up_vector[1], rotate_camera_up_vector[2]])\n",
    "\n",
    "# カメラ画像を取得\n",
    "_, _, rgb_img, depth_img, _ = pybullet.getCameraImage(\n",
    "    width=image_width,\n",
    "    height=image_height,\n",
    "    viewMatrix=view_matrix,\n",
    "    projectionMatrix=projection_matrix,\n",
    "    renderer=pybullet.ER_BULLET_HARDWARE_OPENGL\n",
    ")\n",
    "\n",
    "# 指定した色の物体の位置を取得\n",
    "detect_color_rgb = [0, 0, 255] # 検出したい色を指定（ここでは赤色）\n",
    "pos = detect_color_obj_pose(detect_color_rgb, rgb_img, depth_img)\n",
    "pixel_x = pos[0] # x座標（画像上の位置）\n",
    "pixel_y = pos[1] # y座標（画像上の位置）\n",
    "normal_z = pos[2] # z座標（0～1に正規化された深度）\n",
    "z = far * near / (far - (far - near) * normal_z) # 0～1に正規化された深度を距離[m]に変換\n",
    "x = (pixel_x - image_width//2) * z / f # pixelXを距離[m]に変換\n",
    "y = (pixel_y - image_height//2) * z / f # pixelYを距離[m]に変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[カラーのオブジェクトの位置の推定](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color box obj pose:  -2.0 1.5 0.05\n",
      "estimate color obj pose -1.9903058737195025 1.5078074800905317 0.10001191576652735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ワールド座標系におけるカラーの物体の位置を計算\n",
    "CAMERA_POS = np.array([SIMPLE_CAMERA_X, \n",
    "                      SIMPLE_CAMERA_Y, \n",
    "                      SIMPLE_CAMERA_Z])\n",
    "color_obj_pos_camera = np.array([x, y, z]) # カメラ座標系における物体の位置\n",
    "color_obj_pos_world = CAMERA_POS + R@color_obj_pos_camera # ワールド座標系における物体の位置\n",
    "\n",
    "# ボックスの位置を取得\n",
    "box_pos, box_orn = pybullet.getBasePositionAndOrientation(color_box_id)\n",
    "print(\"color box obj pose: \", box_pos[0], box_pos[1], box_pos[2])\n",
    "print(\"estimate color obj pose\", color_obj_pos_world[0], color_obj_pos_world[1], color_obj_pos_world[2])\n",
    "\n",
    "# Pybuletの画面上に、物体の位置を描画\n",
    "pybullet.addUserDebugLine(CAMERA_POS[:3], color_obj_pos_world[:3], lineColorRGB=[1, 0, 0], lineWidth=5)\n",
    "\n",
    "# ボックスの位置を描画\n",
    "pybullet.addUserDebugText(f\"true box pose ({box_pos[0]:.3f}, {box_pos[1]:.3f}, {box_pos[2]:.3f})\", [4.0, 0.5, 0], textColorRGB=[1, 0, 0], textSize=1.3)\n",
    "pybullet.addUserDebugText(f\"eye to hand, estimate box pose ({color_obj_pos_world[0]:.3f}, {color_obj_pos_world[1]:.3f}, {color_obj_pos_world[2]:.3f})\", [4.0, 1.0, 0.0], textColorRGB=[1, 0, 0], textSize=1.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
